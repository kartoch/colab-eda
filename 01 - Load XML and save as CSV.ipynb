{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - Load XML and save as CSV",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartoch/colab-eda/blob/master/01%20-%20Load%20XML%20and%20save%20as%20CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7izq1AubPJ",
        "colab_type": "text"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "This notebook is an example to load all essence datasets, extract the hierarchical data from the XML and save the tabular corresponding data in CSV.\n",
        "\n",
        "The code to handle the load and save from Google Cloud Storage (GCS) is included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LxQ037egN9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.oauth2 import service_account\n",
        "from google.cloud.storage import client\n",
        "import io\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import json\n",
        "import os.path\n",
        "import logging\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI-AyNN2vgdq",
        "colab_type": "text"
      },
      "source": [
        "# Constants\n",
        "\n",
        "- `START_YEAR` : first year from the essence dataset to load (2007 by  default)\n",
        "- `END_YEAR` : fast year from the essence dataset to load (choose this year minus 1, as the actual year is probably incomplete)\n",
        "- `CACHE_DIRECTORY` : cache directory to save and load file from GCS\n",
        "- `LOG_LEVEL` : log level used by the logging instance `logger`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E0t0boWgOMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_YEAR = 2007\n",
        "END_YEAR = 2007\n",
        "CACHE_DIRECTORY = \"/tmp/\"\n",
        "LOG_LEVEL = \"DEBUG\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX1QEsERMLb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(LOG_LEVEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyqF-zXoxRRG",
        "colab_type": "text"
      },
      "source": [
        "GCS configuration\n",
        "\n",
        "- `SERVICE_ACCOUNT` : copy/paste your service account here\n",
        "- `BUCKET_DATASETS` : bucket containing the original dataset\n",
        "- `BUCKET_PERSONAL` : bucket where you can read/write to save/load files between notebooks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgdolG7meZMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SERVICE_ACCOUNT = json.loads(r\"\"\"{\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"...\",\n",
        "  \"private_key_id\": \"...\",\n",
        "  \"private_key\": \"...\",\n",
        "  \"client_email\": \"...\",\n",
        "  \"client_id\": \"...\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"...\"\n",
        "}\"\"\")\n",
        "BUCKET_DATASETS = \"essence-dataset-eda\"\n",
        "BUCKET_PERSONAL = \"eda-essence-NAME_STUDENT\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcXUMk7Tx3YL",
        "colab_type": "text"
      },
      "source": [
        "# Init and functions for GCS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSiF7j-Jp1Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credentials = service_account.Credentials.from_service_account_info(\n",
        "    SERVICE_ACCOUNT,\n",
        "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        ")\n",
        "\n",
        "client_gcs = client.Client(\n",
        "    credentials=credentials,\n",
        "    project=credentials.project_id,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTcj9_AJOBh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(local_filename, remote_filename, bucket):\n",
        "    if os.path.isfile(local_filename):\n",
        "      logger.info(\"Already donwloaded: %s\", local_filename)\n",
        "    blob = bucket.blob(remote_filename)\n",
        "    blob.download_to_filename(local_filename)\n",
        "\n",
        "def generator_zip_file(client):\n",
        "    bucket = client_gcs.bucket(BUCKET_DATASETS)\n",
        "    for year in range(START_YEAR,END_YEAR+1):\n",
        "        blob_pathname = \"PrixCarburants_annuel_\" + str(year) + \".zip\"\n",
        "        local_filename = CACHE_DIRECTORY + blob_pathname\n",
        "        download_file(local_filename,blob_pathname,bucket)\n",
        "        zip_ref = ZipFile(local_filename)\n",
        "        [xml_filename] = zip_ref.namelist()\n",
        "        yield (zip_ref.open(xml_filename),year)\n",
        "        zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ji2RxP0zTF",
        "colab_type": "text"
      },
      "source": [
        "This is an example to read each file from the essence dataset in a loop. It uses a generator method, which is called for each loop iteration and returns\n",
        "a type (year, file descriptor) of each file in the dataset starting from\n",
        "START_YEAR and ending with END_YEAR.\n",
        "\n",
        "**You probably want to add your code here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3oi1nTmek8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f,year in generator_zip_file(client):\n",
        "    print(f,year)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-kSXbJv19VS",
        "colab_type": "text"
      },
      "source": [
        "This is a code example to send a CSV into GCS.\n",
        "- It creates a dataframe and save it in `/tmp/test.csv`\n",
        "- The method `zip_and_save_file` zips the file to `/tmp/test.csv.zip` and send the file to the bucket with name `test.csv.zip`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOCwrrLtiqfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.DataFrame(\n",
        "    {\"col1\": [1,2,3],\n",
        "     \"col2\": [4,5,6]}\n",
        ").to_csv(path_or_buf=\"/tmp/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYFlZektC4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zip_and_save_file(local_filename, remote_filename, bucket):\n",
        "    zip_local_filename = local_filename + '.zip'\n",
        "    zip_remote_filename = remote_filename + '.zip'\n",
        "    ZipFile(local_filename + '.zip', mode='w').write(local_filename)\n",
        "    blob = bucket.blob(zip_remote_filename)\n",
        "    blob.upload_from_filename(zip_local_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IAcW8O2iMOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_and_save_file(\"/tmp/test.csv\",\"test.csv\", client_gcs.bucket(BUCKET_PERSONAL))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}